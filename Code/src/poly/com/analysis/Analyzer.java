package poly.com.analysis;


import java.io.*;
import java.net.URL;

import gate.*;
import gate.creole.ResourceInstantiationException;
import gate.util.InvalidOffsetException;
import static gate.util.persistence.PersistenceManager.loadObjectFromFile;

import java.io.FileFilter;
import java.io.FileNotFoundException;
import java.io.IOException;
import java.util.*;
import java.util.Map.Entry;

/**
 * The Analyzer class represents an analyzer
 * It loads the Email thread file and analyzes it using tf-idf weight
 * Finally generate a summarization of the keywords and phases
 * 
 * @author Zihang Li, Chao Wang, Yangpan Tao
 * @version 1.3  12/15/2013
 */
public class Analyzer {
	
     private Corpus corpus;
     private Map<String, Integer> tf ;
     private Map<String, Integer> idf ;
     private int totalTermsInDocument = 0;
     private final int totalDocuments = 18777;
     private String fileToPrintOnScreen;
     private String finalResults;
     private String tfidfWords;
     private gate.Document tempDoc = null;
     
     /**
      * Constructor
      * @param filePath The path of the file to be loaded and analyzed
      * @throws Exception
      */
     public Analyzer(String filePath) throws Exception{
    	 /*
    	  * Run Gate two times
    	  * First time for computing the top 10 tfidf words and saving it to a Gazetteer
    	  * Second time for getting the Noun Phase that contains the Gazetteer generated by first time running
    	  */
         init(filePath);
         CorpusProcessing();
         computeTFIDF();      
		 writeTFIDFWordsIntoGazetteer();	 
		 
		 init(filePath);
		 NounPhaseGenerate();
		 Factory.deleteResource(tempDoc);
		 Factory.deleteResource(corpus);
     }
     
     /**
      * Initialize Gate, add the selected file to gate corpus
      * Execute gate with .xgapp file
      * @param filePath  The path of the file to be loaded and analyzed
      * @throws ResourceInstantiationException 
      * @throws Exception
      */
     public void init(String filePath) throws Exception {
        Gate.init();
        File gateHome = Gate.getGateHome();
        if (Gate.getGateHome() == null) Gate.setGateHome(gateHome);
        gate.CorpusController c = ((gate.CorpusController)loadObjectFromFile(
        		new File(System.getProperty("user.dir") + "/plugins/JustAnnie3/application.xgapp")));
        corpus = (Corpus) Factory.createResource("gate.corpora.CorpusImpl");
        String directoryPath = filePath.substring(0, filePath.lastIndexOf("/"));
        final String fileName = filePath.substring(filePath.lastIndexOf("/") + 1);
        URL dir = new File(directoryPath).toURI().toURL();
        
        FileFilter filter = new FileFilter() {
	        public boolean accept(File file) {
	            return file.getName().matches(fileName);
	        }
        };
        
        corpus.populate(dir, filter, "UTF-8", false);  //set the encoding to whatever is the encoding of your files
        c.setCorpus(corpus);
        c.execute();
        System.out.println("Corpus Size" + corpus.size());
        tempDoc = (gate.Document)corpus.get(0);
        
     }
     
     /**
      * Get the useful words and compute the term-frequency for each words.
      * @throws Exception
      */
     public void CorpusProcessing() throws Exception { 
    	 	
    	    /*
    	     * Get the end offset of title and first Email
    	     */
            tf = new HashMap<>();            
            System.out.println(corpus.getDocumentName(0));
            ArrayList<Long> forSort = new ArrayList<>();
            
            for (gate.Annotation a: tempDoc.getAnnotations().get("Email1")) {
                forSort.add(a.getEndNode().getOffset());
            }
            Collections.sort(forSort);
            
            if (!forSort.isEmpty()) {
	            Long offSet = forSort.get(2);
	            
	            /*
	             * Give extra weight to tile and first Email
	             */
	            for (gate.Annotation a: tempDoc.getAnnotations().get("UsefulWords").get(0L,offSet)) {
	                 String termToken = ((String)a.getFeatures().get("string")).toLowerCase();
	                 if (termToken.matches("[a-z]*") && termToken.length() > 2) {
	                     if (!tf.containsKey(termToken)) {
	                         tf.put(termToken,2);
	                     } else {
	                         tf.put(termToken, tf.get(termToken) + 2);
	                     }
	                     totalTermsInDocument++;
	                 }
	            }
            }
            
            /*
             * Count term-frequency for all tokens in annotationSet "UsefulWords"
             */
            for (gate.Annotation a: tempDoc.getAnnotations().get("UsefulWords")) {
                 String termToken = ((String)a.getFeatures().get("string")).toLowerCase();
                 if (termToken.matches("[a-z]*") && termToken.length() > 2) {
                     if (!tf.containsKey(termToken)) {
                         tf.put(termToken,1);
                     } else {
                         tf.put(termToken, tf.get(termToken)+1);
                     }
                     totalTermsInDocument++;
                 }
            }
            
            /*
             * Remove the token from tf  if the token exist in Email head 
             * Main purpose is to remove the person name from the tfidf calculation
             * Otherwise person name will have ranking high in tfidf comparison.
             */
            for (gate.Annotation a : tempDoc.getAnnotations().get("Noise")) {
                 String termToken = ((String)a.getFeatures().get("string")).toLowerCase();
                 if (!termToken.equals("ikea")) {
                	 tf.remove(termToken);
                 }
            }
            
            /*
             * Generate a string that append all the token to it
             * For printing the .pdf onto screen
             */
            StringBuilder toPrint = new StringBuilder();
            
            for (gate.Annotation a: tempDoc.getAnnotations().get("Token")) {
                 String termToken = ((String)a.getFeatures().get("string"));
                 toPrint.append(termToken + " ");
            }
            
            fileToPrintOnScreen = toPrint.toString();

     }
     
     /**
      * Compute TFIDF for every useful token
      * @throws FileNotFoundException
      */
     public void computeTFIDF() throws FileNotFoundException{
    	 /*
    	  * pro2.txt is a preprocess file of newsgroup 18777
    	  * take every token from newsgroup 18777 
    	  * and counts the number of Documents with that token 
    	  */
    	 idf = new HashMap<>();   	 
         Scanner scan = new Scanner(new File(System.getProperty("user.dir") + "/plugins/pro2.txt"));
         while (scan.hasNextLine()) {
             String split[] = scan.nextLine().split(" ");
             idf.put(split[0], Integer.parseInt(split[1]));
         }
         
         /*
          * put every <TFIDF,String> to a treeMap
          */
         TreeMap<TFIDF,String> tfidfOfAll = new TreeMap<>();
         
         for (Map.Entry<String,Integer> a : tf.entrySet()) {
             int numOfOccurrences = a.getValue();
             int numOfDocumentsWithTerm = 1;
             if (idf.containsKey(a.getKey())) {
                 numOfDocumentsWithTerm = idf.get(a.getKey());
             }
             tfidfOfAll.put(new TFIDF(numOfOccurrences,totalTermsInDocument,totalDocuments,numOfDocumentsWithTerm),a.getKey());
         }
         
         /*
          * poll the top 10 tfidf words and save it
          */
         StringBuilder finalString = new StringBuilder("The TF-IDF Ranking (From high to low):" +"\n");
         
         for (int i = 1; i <= 10; i++) {
             Entry<TFIDF,String> largestTFIDF = tfidfOfAll.pollLastEntry();
             tfidfWords = tfidfWords + largestTFIDF.getValue() + "\n";
             finalString.append(largestTFIDF.getValue() + "\n");
         }
         
         finalString.append("\n\n");
         finalResults = finalString.toString();
     }
     
     /*
      * Write the top 10 tfidf words to a Gazetteer for further processing
      */
     public void writeTFIDFWordsIntoGazetteer() throws IOException{
    	 File file = new File(System.getProperty("user.dir") + "/plugins/JustAnnie3/plugins/ANNIE/resources/gazetteer/tfidf.lst");
    	 FileWriter writer = new FileWriter(file);
    	 writer.write(tfidfWords);
    	 writer.flush();
    	 writer.close();  	 
     }
     
     
     /**
      * the Tf-idf annotationSet is taken from the NounPhase Chunker that contains the top 10 tf-idf words
      * Do some String operation to the tf-idf annotationSet and save the result
      * @throws InvalidOffsetException
      */
     public void NounPhaseGenerate() throws InvalidOffsetException {
    	 HashSet<String> hashString = new HashSet<String>(10);
    	 
    	 for (gate.Annotation a: tempDoc.getAnnotations().get("Tfidf")) {
    		 String content = tempDoc.getContent().getContent(a.getStartNode().getOffset(), a.getEndNode().getOffset()).toString();
    		 content = content.replaceAll("\\s+", " ");
    		 
    		 if (!hasDigit(content)) {
    			 String[] contentArray = content.toLowerCase().split("[^a-zA-Z0-9\\s]");
    			 
				 if (contentArray.length == 2 && 
					 (contentArray[0].equals("the") || contentArray[0].equals("a") || contentArray[0].equals("the ")));
				 else if (contentArray.length == 1);
				 else {
					 String c = "";
					 for (int j = 0; j <= contentArray.length - 1; j++) {
						 if (!contentArray[j].equals("com")) {
							 c = c + contentArray[j] + " ";
						 }
					 }
					 if (hashString.size() <= 10) {
						 hashString.add(c);
					 }
				 }
    		 }
    		 
    	 }
    	 
    	 StringBuilder npResultToShow = new StringBuilder("The NP Chunker Results(no order): " + "\n");
    	 
    	 for (String np: hashString) {
    		 np = np.replaceAll("\\s+", " ");
    		 npResultToShow.append(np+ "\n");
    	 }
    	 
    	 System.out.println(hashString.toString());
    	 String temp = npResultToShow.toString();
    	 temp = temp.substring(0,temp.length() - 3);
    	 finalResults = finalResults + temp;
    	 System.out.println(finalResults);
     }
     
     /**
      * This method tests if a string contains digits
      * @param content The string to be examined
      * @return true if has digits, false otherwise
      */
     public static boolean hasDigit(String content) {
         return content.replaceAll("\\d", "").length() != content.length();
     }
     
     /**
      * This method returns the summary of the document
      * @return finalResults  A string representation of the summary
      */
     public String getResult() {
    	 return finalResults;
     }
     
     /**
      * This method returns the file's content
      * @return fileToPrintOnScreen  The content of the original file
      */
     public String getPDF() {
         return fileToPrintOnScreen;
     }
              
}
